# -*- coding: utf-8 -*-
"""Financial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13WqAZZgcuiHRccW12IsVpBtJoKrUjLGC

<a href="https://colab.research.google.com/github/Theophilus03/RAG_Financial_Bot/blob/main/RAG_Financial.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

#streamlit
"""

import os

# Ensure required packages are installed
os.system("pip install -q streamlit")
os.system("pip install -qU 'langchain-chroma>=0.1.2'")
os.system("pip install -q torch transformers accelerate bitsandbytes langchain langchain-community")
os.system("pip install -qU langchain-google-genai")

# Import required libraries
import time
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.ticker as ticker
import streamlit as st
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
import json

def initialize_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    return webdriver.Chrome(options=options)

driver = initialize_driver()

def get_table():
    html = driver.page_source
    soup = BeautifulSoup(html, 'html.parser')
    table = soup.find('div', class_='table yf-1pgoo1f')

    headers = [header.text for header in table.find('div', class_='tableHeader').find_all('div', class_='column')]

    rows = table.find('div', class_='tableBody').find_all('div', class_='row')
    data = [[col.text for col in row.find_all('div', class_='column')] for row in rows]

    return pd.DataFrame(data, columns=headers)

def WebScraping(url):
    driver.get(url)
    expand_button = driver.find_element(By.CLASS_NAME, 'link2-btn')
    expand_button.click()
    time.sleep(1)
    df1 = get_table()

    quarterly_button = driver.find_element(By.ID, 'tab-quarterly')
    quarterly_button.click()
    time.sleep(2)
    df2 = get_table()

    return df1, df2

def main():
    st.set_page_config(page_title="Analisa Laporan Keuangan", page_icon=":money_with_wings:")
    st.header("Chatbot Laporan Keuangan :money_with_wings:")

    with st.sidebar:
        st.subheader("Masukan Tiker Perusahaan")
        tiker = st.text_input("untuk idx tambahkan '.JK' contoh(BBCA.JK)")
        process = st.button("Process")

    if process and tiker:
        st.session_state[f"{tiker}_IS"] = WebScraping(f'https://finance.yahoo.com/quote/{tiker}/financials/')

    if st.button('Quit Driver'):
        driver.quit()
        st.success("WebDriver has been quit.")

if __name__ == '__main__':
    main()
